# lora-llm-finetuning

This repo provides a pipeline for fine-tuning of LLMs using LoRA.
Supports Flash Attention 2, Deepspeed, and gradient checkpointing.
